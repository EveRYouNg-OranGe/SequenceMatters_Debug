{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5f005b-5656-4e3b-9ff4-5275f114129c",
   "metadata": {},
   "source": [
    "# 3DGS训练过程拆解\n",
    "\n",
    "需要提前完成VSR图片超分，得到HR图片集作为高斯模型训练集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc7dceb-a060-4765-b902-27226fb1d70d",
   "metadata": {},
   "source": [
    "## 参数导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04a59c01-ca49-4c78-8d82-2dcf0b571676",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "from random import randint\n",
    "from utils.loss_utils import l1_loss, ssim\n",
    "from gaussian_renderer import render, network_gui \n",
    "import sys\n",
    "from scene import Scene, GaussianModel \n",
    "from utils.general_utils import safe_state\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "from utils.image_utils import psnr\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from arguments import ModelParams, PipelineParams, OptimizationParams\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    TENSORBOARD_FOUND = True\n",
    "except ImportError:\n",
    "    TENSORBOARD_FOUND = False\n",
    "\n",
    "import shutil\n",
    "from utils.general_utils import load_config\n",
    "from vsr.utils_vsr import (\n",
    "    setup_paths_and_params,\n",
    "    load_images,\n",
    "    load_vsr_model,\n",
    "    process_S,\n",
    "    process_ALS,\n",
    "    create_video_from_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "672bb25b-6f63-4464-937b-b5eb3b65306c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get args: Namespace(checkpoint_iterations=[], compute_cov3D_python=False, config='configs/blender.yml', convert_SHs_python=False, data_device='cuda', debug=False, debug_from=-1, densification_interval=100, densify_from_iter=500, densify_grad_threshold=0.0002, densify_until_iter=15000, detect_anomaly=False, eval=True, feature_lr=0.0025, images='images', ip='127.0.0.1', iterations=30000, lambda_dssim=0.2, model_path='../OUTPUTS/3DGS/ship', opacity_lr=0.05, opacity_reset_interval=3000, percent_dense=0.01, port=6009, position_lr_delay_mult=0.01, position_lr_final=1.6e-06, position_lr_init=0.00016, position_lr_max_steps=30000, quiet=False, random_background=False, resolution=-1, rotation_lr=0.001, save_iterations=[7000, 30000, 30000], scaling_lr=0.005, sh_degree=3, source_path='', start_checkpoint=None, test_iterations=[7000, 30000], white_background=False)\n",
      "\n",
      "source_path: ../OUTPUTS/HR/ship\n",
      "\n",
      "hr_source_path: ../NERF_SYNTHETIC/ship\n",
      "\n",
      "lr_source_path: ../OUTPUTS/LR/ship\n",
      "\n",
      "gt_source_path: ../NERF_SYNTHETIC/ship\n",
      "\n",
      "Optimizing ../OUTPUTS/3DGS/ship\n",
      "sh_degree                : 3\n",
      "source_path              : ../OUTPUTS/HR/ship\n",
      "model_path               : ../OUTPUTS/3DGS/ship\n",
      "images                   : images\n",
      "resolution               : -1\n",
      "white_background         : False\n",
      "data_device              : cuda\n",
      "eval                     : True\n",
      "iterations               : 30000\n",
      "position_lr_init         : 0.00016\n",
      "position_lr_final        : 1.6e-06\n",
      "position_lr_delay_mult   : 0.01\n",
      "position_lr_max_steps    : 30000\n",
      "feature_lr               : 0.0025\n",
      "opacity_lr               : 0.05\n",
      "scaling_lr               : 0.005\n",
      "rotation_lr              : 0.001\n",
      "percent_dense            : 0.01\n",
      "lambda_dssim             : 0.2\n",
      "densification_interval   : 100\n",
      "opacity_reset_interval   : 3000\n",
      "densify_from_iter        : 500\n",
      "densify_until_iter       : 15000\n",
      "densify_grad_threshold   : 0.0002\n",
      "random_background        : False\n",
      "convert_SHs_python       : False\n",
      "compute_cov3D_python     : False\n",
      "debug                    : False\n",
      "ip                       : 127.0.0.1\n",
      "port                     : 6009\n",
      "debug_from               : -1\n",
      "detect_anomaly           : False\n",
      "test_iterations          : [7000, 30000]\n",
      "save_iterations          : [7000, 30000, 30000]\n",
      "quiet                    : False\n",
      "checkpoint_iterations    : []\n",
      "start_checkpoint         : None\n",
      "config                   : configs/blender.yml\n",
      "hr_source_dir            : ../NERF_SYNTHETIC\n",
      "lr_source_dir            : ../OUTPUTS/LR\n",
      "vsr_save_dir             : ../OUTPUTS/HR\n",
      "video_save_path          : None\n",
      "vsr_model                : psrt\n",
      "spynet_path              : None\n",
      "vsr_model_path           : None\n",
      "downscale_factor         : 4\n",
      "subpixel                 : bicubic\n",
      "als                      : False\n",
      "num_images_in_sequence   : 100\n",
      "similarity               : feature\n",
      "thres_values             : [45]\n",
      "lambda_tex               : 0.6\n",
      "hr_source_path           : ../NERF_SYNTHETIC/ship\n",
      "lr_source_path           : ../OUTPUTS/LR/ship\n",
      "gt_source_path           : ../NERF_SYNTHETIC/ship\n"
     ]
    }
   ],
   "source": [
    "# Set up command line argument parser\n",
    "parser = ArgumentParser(description=\"Training script parameters\")\n",
    "lp = ModelParams(parser)\n",
    "op = OptimizationParams(parser)\n",
    "pp = PipelineParams(parser)\n",
    "parser.add_argument('--ip', type=str, default=\"127.0.0.1\")\n",
    "parser.add_argument('--port', type=int, default=6009)\n",
    "parser.add_argument('--debug_from', type=int, default=-1)\n",
    "parser.add_argument('--detect_anomaly', action='store_true', default=False)\n",
    "parser.add_argument(\"--test_iterations\", nargs=\"+\", type=int, default=[7_000, 30_000])\n",
    "parser.add_argument(\"--save_iterations\", nargs=\"+\", type=int, default=[7_000, 30_000])\n",
    "parser.add_argument(\"--quiet\", action=\"store_true\")\n",
    "parser.add_argument(\"--checkpoint_iterations\", nargs=\"+\", type=int, default=[])\n",
    "parser.add_argument(\"--start_checkpoint\", type=str, default = None)\n",
    "\n",
    "parser.add_argument(\"--config\", type=str, default=None, help=\"Path to configuration YAML file\")\n",
    "\n",
    "# -m : args.model_path, 3d模型保存路径，最后一个子文件夹必须为场景名，用来解析识别场景\n",
    "args = parser.parse_args([\n",
    "    \"-m\", \"../OUTPUTS/3DGS/ship\",\n",
    "    \"--eval\", \n",
    "    \"--config\", \"configs/blender.yml\"\n",
    "])\n",
    "args.save_iterations.append(args.iterations)\n",
    "\n",
    "print(f\"\\nGet args: {args}\\n\")\n",
    "\n",
    "args = load_config(args)\n",
    "print(\"Optimizing \" + args.model_path)\n",
    "# 遍历并打印\n",
    "for key, value in vars(args).items():\n",
    "    print(f\"{key:<25}: {value}\")\n",
    "\n",
    "# Initialize system state (RNG)\n",
    "# safe_state(args.quiet)\n",
    "\n",
    "# Start GUI server, configure and run training\n",
    "# network_gui.init(args.ip, args.port)\n",
    "# torch.autograd.set_detect_anomaly(args.detect_anomaly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abcdf7b-0ca7-4a90-8b84-af7a9c13b921",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9972000e-21cd-4804-b8d1-d31aec3ef6b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' 训练所需参数 ''' \n",
    "lambda_tex=0.40\n",
    "subpixel=\"avg\"\n",
    "(\n",
    "    dataset, opt, pipe, testing_iterations, saving_iterations, \n",
    "    checkpoint_iterations, checkpoint, debug_from, lambda_tex, subpixel\n",
    ") = (\n",
    "    lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, \n",
    "    args.checkpoint_iterations, args.start_checkpoint, args.debug_from, args.lambda_tex, \n",
    "    args.subpixel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a9a15a9-e588-4ee5-bf42-ef61e9585716",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder: ../OUTPUTS/3DGS/ship\n"
     ]
    }
   ],
   "source": [
    "''' 1. 准备日志和输出目录 '''\n",
    "first_iter = 0\n",
    "\n",
    "# args.model_path即3d高斯模型存储路径\n",
    "if not args.model_path:\n",
    "    # 调用环境变量OAR_JOB_ID， 变量通常用于集群或调度系统（如 OAR、SLURM）中，用来表示任务的唯一编号； \n",
    "    # 如果不是这种环境， 那就用随机字符串的前十位；\n",
    "    if os.getenv('OAR_JOB_ID'):\n",
    "        unique_str=os.getenv('OAR_JOB_ID')\n",
    "    else:\n",
    "        unique_str = str(uuid.uuid4())\n",
    "        args.model_path = os.path.join(\"./output/\", unique_str[0:10])\n",
    "\n",
    "# Set up output folder\n",
    "print(\"Output folder: {}\".format(args.model_path))\n",
    "os.makedirs(args.model_path, exist_ok = True)\n",
    "# 生成一个cfg文件，写入参数\n",
    "with open(os.path.join(args.model_path, \"cfg_args\"), 'w') as cfg_log_f:\n",
    "    cfg_log_f.write(str(Namespace(**vars(args))))\n",
    "\n",
    "# Create Tensorboard writer\n",
    "tb_writer = None\n",
    "if TENSORBOARD_FOUND:\n",
    "    tb_writer = SummaryWriter(args.model_path)\n",
    "else:\n",
    "    print(\"Tensorboard not available: not logging progress\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8747ab11-b510-46ef-ab2a-5d7eeba5b14a",
   "metadata": {},
   "source": [
    "高斯模型，需进一步了解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "931e0630-3c45-42e4-8bab-915717ecf6d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' 2. 初始化高斯模型 '''\n",
    "gaussians = GaussianModel(dataset.sh_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5ae032c-9f4a-438d-b09d-115eb1ca20b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found transforms_train.json file, assuming Blender data set!\n",
      "Reading Training Transforms\n",
      "Reading Test Transforms\n",
      "Loading Training Cameras\n",
      "Loading Test Cameras\n",
      "Number of points at initialisation :  100000\n"
     ]
    }
   ],
   "source": [
    "''' 3. 创建场景（加载训练相机）'''\n",
    "scene = Scene(dataset, gaussians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a14a237e-dabc-4021-b59f-c623ea4e0190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' 4. 设置优化器 '''\n",
    "gaussians.training_setup(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab0d7ff5-08c3-48bd-ae9d-da3e5aebad18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' 5. 恢复检查点（如果提供） '''\n",
    "if checkpoint:\n",
    "    (model_params, first_iter) = torch.load(checkpoint)\n",
    "    gaussians.restore(model_params, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfe7ea6a-670d-45f9-80bd-21db1ecd84d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' 训练实时数据报告 （删除了tensorboard相关代码） '''\n",
    "def training_report(tb_writer, iteration, Ll1, loss, l1_loss, elapsed, testing_iterations, scene, renderFunc, renderArgs):\n",
    "\n",
    "    # Report test and samples of training set\n",
    "    if iteration in testing_iterations:\n",
    "        torch.cuda.empty_cache()\n",
    "        validation_configs = ({'name': 'test', 'cameras' : scene.getTestCameras()}, \n",
    "                              {'name': 'train', 'cameras' : [scene.getTrainCameras()[idx % len(scene.getTrainCameras())] for idx in range(5, 30, 5)]})\n",
    "\n",
    "        for config in validation_configs:\n",
    "            if config['cameras'] and len(config['cameras']) > 0:\n",
    "                l1_test = 0.0\n",
    "                psnr_test = 0.0\n",
    "                for idx, viewpoint in enumerate(config['cameras']):\n",
    "                    image = torch.clamp(renderFunc(viewpoint, scene.gaussians, *renderArgs)[\"render\"], 0.0, 1.0)\n",
    "                    gt_image = torch.clamp(viewpoint.original_image.to(\"cuda\"), 0.0, 1.0)\n",
    "                    \n",
    "                    l1_test += l1_loss(image, gt_image).mean().double()\n",
    "                    psnr_test += psnr(image, gt_image).mean().double()\n",
    "                psnr_test /= len(config['cameras'])\n",
    "                l1_test /= len(config['cameras'])          \n",
    "                print(\"\\n[ITER {}] Evaluating {}: L1 {} PSNR {}\".format(iteration, config['name'], l1_test, psnr_test))\n",
    "        \n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89ab77b5-a04f-42c5-a902-32ea7b9699a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 初始化一个背景色tensor\n",
    "bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]\n",
    "background = torch.tensor(bg_color, dtype=torch.float32, device=\"cuda\")\n",
    "'''\n",
    ">>background\n",
    "tensor([0., 0., 0.], device='cuda:0')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffe18748-daf4-4a5d-85dc-67d57283be5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 计时与同步工具\n",
    "iter_start = torch.cuda.Event(enable_timing = True)\n",
    "iter_end = torch.cuda.Event(enable_timing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd444c48-4f20-412e-9da4-5709512e2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewpoint_stack = None\n",
    "# 定义了一个二维平均池化层\n",
    "'''用于对输入特征图（如图片或卷积层输出）进行降采样。 它会将输入划分成若干个小区域（称为窗口或 kernel）， 然后在每个区域中计算所有像素的平均值，\n",
    "从而实现： 降低分辨率、减少计算量、保留整体特征趋势。'''\n",
    "avg_kernel = torch.nn.AvgPool2d(4, stride=4)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
