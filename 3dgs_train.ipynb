{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5f005b-5656-4e3b-9ff4-5275f114129c",
   "metadata": {},
   "source": [
    "# 3DGS训练过程拆解\n",
    "\n",
    "需要提前完成VSR图片超分，得到HR图片集作为高斯模型训练集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc7dceb-a060-4765-b902-27226fb1d70d",
   "metadata": {},
   "source": [
    "## 参数导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04a59c01-ca49-4c78-8d82-2dcf0b571676",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "from random import randint\n",
    "from utils.loss_utils import l1_loss, ssim\n",
    "from gaussian_renderer import render, network_gui \n",
    "import sys\n",
    "from scene import Scene, GaussianModel \n",
    "from utils.general_utils import safe_state\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "from utils.image_utils import psnr\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from arguments import ModelParams, PipelineParams, OptimizationParams\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    TENSORBOARD_FOUND = True\n",
    "except ImportError:\n",
    "    TENSORBOARD_FOUND = False\n",
    "\n",
    "import shutil\n",
    "from utils.general_utils import load_config\n",
    "from vsr.utils_vsr import (\n",
    "    setup_paths_and_params,\n",
    "    load_images,\n",
    "    load_vsr_model,\n",
    "    process_S,\n",
    "    process_ALS,\n",
    "    create_video_from_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "672bb25b-6f63-4464-937b-b5eb3b65306c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get args: Namespace(checkpoint_iterations=[], compute_cov3D_python=False, config='configs/blender.yml', convert_SHs_python=False, data_device='cuda', debug=False, debug_from=-1, densification_interval=100, densify_from_iter=500, densify_grad_threshold=0.0002, densify_until_iter=15000, detect_anomaly=False, eval=True, feature_lr=0.0025, images='images', ip='127.0.0.1', iterations=30000, lambda_dssim=0.2, model_path='../OUTPUTS/3DGS/ship', opacity_lr=0.05, opacity_reset_interval=3000, percent_dense=0.01, port=6009, position_lr_delay_mult=0.01, position_lr_final=1.6e-06, position_lr_init=0.00016, position_lr_max_steps=30000, quiet=False, random_background=False, resolution=-1, rotation_lr=0.001, save_iterations=[7000, 30000, 30000], scaling_lr=0.005, sh_degree=3, source_path='', start_checkpoint=None, test_iterations=[7000, 30000], white_background=False)\n",
      "\n",
      "source_path: ../OUTPUTS/HR/ship\n",
      "\n",
      "hr_source_path: ../NERF_SYNTHETIC/ship\n",
      "\n",
      "lr_source_path: ../OUTPUTS/LR/ship\n",
      "\n",
      "gt_source_path: ../NERF_SYNTHETIC/ship\n",
      "\n",
      "Optimizing ../OUTPUTS/3DGS/ship\n",
      "sh_degree                : 3\n",
      "source_path              : ../OUTPUTS/HR/ship\n",
      "model_path               : ../OUTPUTS/3DGS/ship\n",
      "images                   : images\n",
      "resolution               : -1\n",
      "white_background         : False\n",
      "data_device              : cuda\n",
      "eval                     : True\n",
      "iterations               : 30000\n",
      "position_lr_init         : 0.00016\n",
      "position_lr_final        : 1.6e-06\n",
      "position_lr_delay_mult   : 0.01\n",
      "position_lr_max_steps    : 30000\n",
      "feature_lr               : 0.0025\n",
      "opacity_lr               : 0.05\n",
      "scaling_lr               : 0.005\n",
      "rotation_lr              : 0.001\n",
      "percent_dense            : 0.01\n",
      "lambda_dssim             : 0.2\n",
      "densification_interval   : 100\n",
      "opacity_reset_interval   : 3000\n",
      "densify_from_iter        : 500\n",
      "densify_until_iter       : 15000\n",
      "densify_grad_threshold   : 0.0002\n",
      "random_background        : False\n",
      "convert_SHs_python       : False\n",
      "compute_cov3D_python     : False\n",
      "debug                    : False\n",
      "ip                       : 127.0.0.1\n",
      "port                     : 6009\n",
      "debug_from               : -1\n",
      "detect_anomaly           : False\n",
      "test_iterations          : [7000, 30000]\n",
      "save_iterations          : [7000, 30000, 30000]\n",
      "quiet                    : False\n",
      "checkpoint_iterations    : []\n",
      "start_checkpoint         : None\n",
      "config                   : configs/blender.yml\n",
      "hr_source_dir            : ../NERF_SYNTHETIC\n",
      "lr_source_dir            : ../OUTPUTS/LR\n",
      "vsr_save_dir             : ../OUTPUTS/HR\n",
      "video_save_path          : None\n",
      "vsr_model                : psrt\n",
      "spynet_path              : None\n",
      "vsr_model_path           : None\n",
      "downscale_factor         : 4\n",
      "subpixel                 : bicubic\n",
      "als                      : False\n",
      "num_images_in_sequence   : 100\n",
      "similarity               : feature\n",
      "thres_values             : [45]\n",
      "lambda_tex               : 0.6\n",
      "hr_source_path           : ../NERF_SYNTHETIC/ship\n",
      "lr_source_path           : ../OUTPUTS/LR/ship\n",
      "gt_source_path           : ../NERF_SYNTHETIC/ship\n"
     ]
    }
   ],
   "source": [
    "# Set up command line argument parser\n",
    "parser = ArgumentParser(description=\"Training script parameters\")\n",
    "lp = ModelParams(parser)\n",
    "op = OptimizationParams(parser)\n",
    "pp = PipelineParams(parser)\n",
    "parser.add_argument('--ip', type=str, default=\"127.0.0.1\")\n",
    "parser.add_argument('--port', type=int, default=6009)\n",
    "parser.add_argument('--debug_from', type=int, default=-1)\n",
    "parser.add_argument('--detect_anomaly', action='store_true', default=False)\n",
    "parser.add_argument(\"--test_iterations\", nargs=\"+\", type=int, default=[7_000, 30_000])\n",
    "parser.add_argument(\"--save_iterations\", nargs=\"+\", type=int, default=[7_000, 30_000])\n",
    "parser.add_argument(\"--quiet\", action=\"store_true\")\n",
    "parser.add_argument(\"--checkpoint_iterations\", nargs=\"+\", type=int, default=[])\n",
    "parser.add_argument(\"--start_checkpoint\", type=str, default = None)\n",
    "\n",
    "parser.add_argument(\"--config\", type=str, default=None, help=\"Path to configuration YAML file\")\n",
    "\n",
    "# -m : args.model_path, 3d模型保存路径，最后一个子文件夹必须为场景名，用来解析识别场景\n",
    "args = parser.parse_args([\n",
    "    \"-m\", \"../OUTPUTS/3DGS/ship\",\n",
    "    \"--eval\", \n",
    "    \"--config\", \"configs/blender.yml\"\n",
    "])\n",
    "args.save_iterations.append(args.iterations)\n",
    "\n",
    "print(f\"\\nGet args: {args}\\n\")\n",
    "\n",
    "args = load_config(args)\n",
    "print(\"Optimizing \" + args.model_path)\n",
    "# 遍历并打印\n",
    "for key, value in vars(args).items():\n",
    "    print(f\"{key:<25}: {value}\")\n",
    "\n",
    "# Initialize system state (RNG)\n",
    "# safe_state(args.quiet)\n",
    "\n",
    "# Start GUI server, configure and run training\n",
    "# network_gui.init(args.ip, args.port)\n",
    "# torch.autograd.set_detect_anomaly(args.detect_anomaly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abcdf7b-0ca7-4a90-8b84-af7a9c13b921",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9972000e-21cd-4804-b8d1-d31aec3ef6b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' 训练所需参数 ''' \n",
    "lambda_tex=0.40\n",
    "subpixel=\"avg\"\n",
    "(\n",
    "    dataset, opt, pipe, testing_iterations, saving_iterations, \n",
    "    checkpoint_iterations, checkpoint, debug_from, lambda_tex, subpixel\n",
    ") = (\n",
    "    lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, \n",
    "    args.checkpoint_iterations, args.start_checkpoint, args.debug_from, args.lambda_tex, \n",
    "    args.subpixel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a9a15a9-e588-4ee5-bf42-ef61e9585716",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder: ../OUTPUTS/3DGS/ship\n"
     ]
    }
   ],
   "source": [
    "''' 1. 准备日志和输出目录 '''\n",
    "first_iter = 0\n",
    "\n",
    "# args.model_path即3d高斯模型存储路径\n",
    "if not args.model_path:\n",
    "    # 调用环境变量OAR_JOB_ID， 变量通常用于集群或调度系统（如 OAR、SLURM）中，用来表示任务的唯一编号； \n",
    "    # 如果不是这种环境， 那就用随机字符串的前十位；\n",
    "    if os.getenv('OAR_JOB_ID'):\n",
    "        unique_str=os.getenv('OAR_JOB_ID')\n",
    "    else:\n",
    "        unique_str = str(uuid.uuid4())\n",
    "        args.model_path = os.path.join(\"./output/\", unique_str[0:10])\n",
    "\n",
    "# Set up output folder\n",
    "print(\"Output folder: {}\".format(args.model_path))\n",
    "os.makedirs(args.model_path, exist_ok = True)\n",
    "# 生成一个cfg文件，写入参数\n",
    "with open(os.path.join(args.model_path, \"cfg_args\"), 'w') as cfg_log_f:\n",
    "    cfg_log_f.write(str(Namespace(**vars(args))))\n",
    "\n",
    "# Create Tensorboard writer\n",
    "tb_writer = None\n",
    "if TENSORBOARD_FOUND:\n",
    "    tb_writer = SummaryWriter(args.model_path)\n",
    "else:\n",
    "    print(\"Tensorboard not available: not logging progress\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8747ab11-b510-46ef-ab2a-5d7eeba5b14a",
   "metadata": {},
   "source": [
    "高斯模型，需进一步了解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "931e0630-3c45-42e4-8bab-915717ecf6d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' 2. 初始化高斯模型 '''\n",
    "gaussians = GaussianModel(dataset.sh_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ae032c-9f4a-438d-b09d-115eb1ca20b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found transforms_train.json file, assuming Blender data set!\n",
      "Reading Training Transforms\n",
      "Reading Test Transforms\n",
      "Loading Training Cameras\n",
      "Loading Test Cameras\n",
      "Number of points at initialisation :  100000\n"
     ]
    }
   ],
   "source": [
    "''' 3. 创建场景（加载训练相机）'''\n",
    "scene = Scene(dataset, gaussians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a14a237e-dabc-4021-b59f-c623ea4e0190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' 4. 设置优化器 '''\n",
    "gaussians.training_setup(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab0d7ff5-08c3-48bd-ae9d-da3e5aebad18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' 5. 恢复检查点（如果提供） '''\n",
    "if checkpoint:\n",
    "    (model_params, first_iter) = torch.load(checkpoint)\n",
    "    gaussians.restore(model_params, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfe7ea6a-670d-45f9-80bd-21db1ecd84d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' 训练实时数据报告 （删除了tensorboard相关代码） '''\n",
    "def training_report(tb_writer, iteration, Ll1, loss, l1_loss, elapsed, testing_iterations, scene, renderFunc, renderArgs):\n",
    "\n",
    "    # Report test and samples of training set\n",
    "    if iteration in testing_iterations:\n",
    "        torch.cuda.empty_cache()\n",
    "        validation_configs = ({'name': 'test', 'cameras' : scene.getTestCameras()}, \n",
    "                              {'name': 'train', 'cameras' : [scene.getTrainCameras()[idx % len(scene.getTrainCameras())] for idx in range(5, 30, 5)]})\n",
    "\n",
    "        for config in validation_configs:\n",
    "            if config['cameras'] and len(config['cameras']) > 0:\n",
    "                l1_test = 0.0\n",
    "                psnr_test = 0.0\n",
    "                for idx, viewpoint in enumerate(config['cameras']):\n",
    "                    image = torch.clamp(renderFunc(viewpoint, scene.gaussians, *renderArgs)[\"render\"], 0.0, 1.0)\n",
    "                    gt_image = torch.clamp(viewpoint.original_image.to(\"cuda\"), 0.0, 1.0)\n",
    "                    \n",
    "                    l1_test += l1_loss(image, gt_image).mean().double()\n",
    "                    psnr_test += psnr(image, gt_image).mean().double()\n",
    "                psnr_test /= len(config['cameras'])\n",
    "                l1_test /= len(config['cameras'])          \n",
    "                print(\"\\n[ITER {}] Evaluating {}: L1 {} PSNR {}\".format(iteration, config['name'], l1_test, psnr_test))\n",
    "        \n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89ab77b5-a04f-42c5-a902-32ea7b9699a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n>>background\\ntensor([0., 0., 0.], device='cuda:0')\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化一个背景色tensor\n",
    "bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]\n",
    "background = torch.tensor(bg_color, dtype=torch.float32, device=\"cuda\")\n",
    "'''\n",
    ">>background\n",
    "tensor([0., 0., 0.], device='cuda:0')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe18748-daf4-4a5d-85dc-67d57283be5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 计时与同步工具\n",
    "iter_start = torch.cuda.Event(enable_timing = True)\n",
    "iter_end = torch.cuda.Event(enable_timing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd444c48-4f20-412e-9da4-5709512e2e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "viewpoint_stack = None\n",
    "# 定义了一个二维平均池化层\n",
    "'''用于对输入特征图（如图片或卷积层输出）进行降采样。 它会将输入划分成若干个小区域（称为窗口或 kernel）， 然后在每个区域中计算所有像素的平均值，\n",
    "从而实现： 降低分辨率、减少计算量、保留整体特征趋势。'''\n",
    "avg_kernel = torch.nn.AvgPool2d(4, stride=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47ab4f61-d9f7-45d0-a10f-269be254f7c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  23%|██▎       | 7000/30000 [01:27<04:59, 76.88it/s, Loss=0.0149656] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ITER 7000] Evaluating test: L1 0.014680621949955822 PSNR 28.988281030654907\n",
      "\n",
      "[ITER 7000] Evaluating train: L1 0.009524905867874623 PSNR 33.56439552307129\n",
      "\n",
      "[ITER 7000] Saving Gaussians\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress: 100%|██████████| 30000/30000 [06:04<00:00, 82.24it/s, Loss=0.0107401] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ITER 30000] Evaluating test: L1 0.013974122772924603 PSNR 29.377678155899048\n",
      "\n",
      "[ITER 30000] Evaluating train: L1 0.006740763317793608 PSNR 36.52185745239258\n",
      "\n",
      "[ITER 30000] Saving Gaussians\n"
     ]
    }
   ],
   "source": [
    "ema_loss_for_log = 0.0\n",
    "progress_bar = tqdm(range(first_iter, opt.iterations), desc=\"Training progress\")\n",
    "first_iter += 1\n",
    "for iteration in range(first_iter, opt.iterations + 1):        \n",
    "    # if network_gui.conn == None:\n",
    "    #     network_gui.try_connect()\n",
    "    # while network_gui.conn != None:\n",
    "    #     try:\n",
    "    #         net_image_bytes = None\n",
    "    #         custom_cam, do_training, pipe.convert_SHs_python, pipe.compute_cov3D_python, keep_alive, scaling_modifer = network_gui.receive()\n",
    "    #         if custom_cam != None:\n",
    "    #             net_image = render(custom_cam, gaussians, pipe, background, scaling_modifer)[\"render\"]\n",
    "    #             net_image_bytes = memoryview((torch.clamp(net_image, min=0, max=1.0) * 255).byte().permute(1, 2, 0).contiguous().cpu().numpy())\n",
    "    #         network_gui.send(net_image_bytes, dataset.source_path)\n",
    "    #         if do_training and ((iteration < int(opt.iterations)) or not keep_alive):\n",
    "    #             break\n",
    "    #     except Exception as e:\n",
    "    #         network_gui.conn = None\n",
    "\n",
    "    iter_start.record()  # 开始计时 \n",
    "\n",
    "    gaussians.update_learning_rate(iteration) # 更新学习率\n",
    "\n",
    "    # Every 1000 its we increase the levels of SH up to a maximum degree\n",
    "    # 每迭代1000次， 提高SH水平， 直到最高水平\n",
    "    if iteration % 1000 == 0:\n",
    "        gaussians.oneupSHdegree() # active_sh_degree += 1\n",
    "    '''每1000次迭代增加球谐函数的度数; 球谐函数用于表示外观变化，更高度数能捕捉更复杂的细节'''\n",
    "        \n",
    "    ### HR scale\n",
    "    # Pick a random Camera 选择一个相机\n",
    "    if not viewpoint_stack:\n",
    "        viewpoint_stack = scene.getTrainCameras().copy()\n",
    "    idx_cam = randint(0, len(viewpoint_stack)-1)\n",
    "    viewpoint_cam = viewpoint_stack.pop(idx_cam)\n",
    "\n",
    "    # Render\n",
    "    # 在迭代次数到达一定数值时开启debug模式\n",
    "    if (iteration - 1) == debug_from:\n",
    "        pipe.debug = True\n",
    "\n",
    "    bg = torch.rand((3), device=\"cuda\") if opt.random_background else background # 随机背景或者固定背景 （为什么需要随机背景？）\n",
    "    # 高分辨率渲染\n",
    "    render_pkg = render(viewpoint_cam, gaussians, pipe, bg)\n",
    "    image, viewspace_point_tensor, visibility_filter, radii = render_pkg[\"render\"], render_pkg[\"viewspace_points\"], render_pkg[\"visibility_filter\"], render_pkg[\"radii\"]\n",
    "\n",
    "    # Loss 高分辨率损失函数\n",
    "    gt_image = viewpoint_cam.original_image.cuda()\n",
    "    Ll1 = l1_loss(image, gt_image)\n",
    "    loss_tex = (1.0 - opt.lambda_dssim) * Ll1 + opt.lambda_dssim * (1.0 - ssim(image, gt_image))\n",
    "\n",
    "    ### LR scale\n",
    "    # Pick a random Camera\n",
    "    # 高分辨率渲染结果降采样到低分辨率； 使用平均池化或者双三次插值\n",
    "    if subpixel == 'avg':\n",
    "        image_avg = avg_kernel(image)\n",
    "    elif subpixel == 'bicubic':\n",
    "        image_avg = torch.nn.functional.interpolate(image.unsqueeze(0), scale_factor=0.25, mode='bicubic', antialias=True).squeeze(0)\n",
    "    else:\n",
    "        raise Exception(\"Wrong sub-pixel option\")\n",
    "\n",
    "    gt_image_lr = viewpoint_cam.original_image_lr.cuda()\n",
    "    # 确保低分辨率GT图像与下采样结果尺寸匹配\n",
    "    if image_avg.shape != gt_image_lr.shape: \n",
    "        # import torch.nn.functional as F\n",
    "        gt_image_lr = torch.nn.functional.interpolate(gt_image.unsqueeze(0), size=image_avg.size()[-2:], mode='bicubic', antialias=True).squeeze(0)\n",
    "\n",
    "    # Loss 计算低分辨率损失函数\n",
    "    Ll1_sp = l1_loss(image_avg, gt_image_lr)\n",
    "    loss_sp = (1.0 - opt.lambda_dssim) * Ll1_sp + opt.lambda_dssim * (1.0 - ssim(image_avg, gt_image_lr))\n",
    "\n",
    "#     if iteration == opt.iterations - 5000:\n",
    "#         import torchvision.transforms as transforms\n",
    "#         from PIL import Image\n",
    "\n",
    "#         to_pil_image = transforms.ToPILImage()\n",
    "\n",
    "#         gt_image_lr_pil = to_pil_image(gt_image_lr)\n",
    "#         gt_image_lr_pil.save(\"gt_image_lr_pil.png\")\n",
    "\n",
    "#         image_avg_pil  = to_pil_image(image_avg)\n",
    "#         image_avg_pil.save(\"image_avg_pil.png\")\n",
    "\n",
    "    # 最终损失计算和反向传播\n",
    "    lambda_tex_scheduled = lambda_tex\n",
    "    loss = (1.0 - lambda_tex_scheduled) * loss_sp + lambda_tex_scheduled * loss_tex\n",
    "    loss.backward()\n",
    "\n",
    "    iter_end.record()\n",
    "\n",
    "    # 由高斯点云渲染3D模型\n",
    "    with torch.no_grad():\n",
    "        # Progress bar\n",
    "        ema_loss_for_log = 0.4 * loss.item() + 0.6 * ema_loss_for_log # EMA损失：使用0.4/0.6权重计算平滑损失，避免波动\n",
    "        if iteration % 10 == 0:\n",
    "            progress_bar.set_postfix({\"Loss\": f\"{ema_loss_for_log:.{7}f}\"})\n",
    "            progress_bar.update(10)\n",
    "        if iteration == opt.iterations:\n",
    "            progress_bar.close()\n",
    "\n",
    "        # Log and save 记录损失、渲染时间等指标，可能包括测试集评估\n",
    "        training_report(tb_writer, iteration, Ll1, loss, l1_loss, iter_start.elapsed_time(iter_end), testing_iterations, scene, render, (pipe, background))\n",
    "        # 保存设定的迭代点处的模型\n",
    "        if (iteration in saving_iterations):\n",
    "            print(\"\\n[ITER {}] Saving Gaussians\".format(iteration))\n",
    "            scene.save(iteration)\n",
    "\n",
    "        # Densification\n",
    "        # 密度控制； 在细节不足或误差大的地方自动“加点”； 在冗余或不可见区域“删点”。\n",
    "        if iteration < opt.densify_until_iter:\n",
    "            # Keep track of max radii in image-space for pruning\n",
    "            gaussians.max_radii2D[visibility_filter] = torch.max(gaussians.max_radii2D[visibility_filter], radii[visibility_filter])\n",
    "            gaussians.add_densification_stats(viewspace_point_tensor, visibility_filter)\n",
    "\n",
    "            if iteration > opt.densify_from_iter and iteration % opt.densification_interval == 0:\n",
    "                size_threshold = 20 if iteration > opt.opacity_reset_interval else None\n",
    "                gaussians.densify_and_prune(opt.densify_grad_threshold, 0.005, scene.cameras_extent, size_threshold)\n",
    "\n",
    "            if iteration % opt.opacity_reset_interval == 0 or (dataset.white_background and iteration == opt.densify_from_iter):\n",
    "                gaussians.reset_opacity()\n",
    "\n",
    "        # Optimizer step 优化\n",
    "        if iteration < opt.iterations:\n",
    "            gaussians.optimizer.step() # 执行梯度下降\n",
    "            gaussians.optimizer.zero_grad(set_to_none = True) # 为下一次迭代准备，set_to_none=True节省内存\n",
    "\n",
    "        # 输出保存高精度3D Gaussian点云模型\n",
    "        if (iteration in checkpoint_iterations):\n",
    "            print(\"\\n[ITER {}] Saving Checkpoint\".format(iteration))\n",
    "            torch.save((gaussians.capture(), iteration), scene.model_path + \"/chkpnt\" + str(iteration) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e4856-2673-4f99-ba5e-a363937b638c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
