{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10e9a6fe-9a46-412c-9d5c-b24de85708c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.system(\"CUDA_VISIBLE_DEVICES=$GPU python scripts/downscale_dataset_blender.py --config configs/blender.yml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5398a134-94f4-4f41-be94-98e31716a696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T14:57:26.146550Z",
     "iopub.status.busy": "2025-11-03T14:57:26.145805Z",
     "iopub.status.idle": "2025-11-03T14:57:28.718757Z",
     "shell.execute_reply": "2025-11-03T14:57:28.717611Z",
     "shell.execute_reply.started": "2025-11-03T14:57:26.146487Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "# 强制使用CPU（无CUDA版本）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "from random import randint\n",
    "from utils.loss_utils import l1_loss, ssim\n",
    "from gaussian_renderer import render, network_gui \n",
    "import sys\n",
    "from scene import Scene, GaussianModel \n",
    "from utils.general_utils import safe_state\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "from utils.image_utils import psnr\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from arguments import ModelParams, PipelineParams, OptimizationParams\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    TENSORBOARD_FOUND = True\n",
    "except ImportError:\n",
    "    TENSORBOARD_FOUND = False\n",
    "\n",
    "import shutil\n",
    "from utils.general_utils import load_config\n",
    "from vsr.utils_vsr import (\n",
    "    setup_paths_and_params,\n",
    "    load_images,\n",
    "    load_vsr_model,\n",
    "    process_S,\n",
    "    process_ALS,\n",
    "    create_video_from_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5dcd8ec-39ad-4443-bf0b-8f9c8a1519fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T14:57:28.720856Z",
     "iopub.status.busy": "2025-11-03T14:57:28.720374Z",
     "iopub.status.idle": "2025-11-03T14:57:28.735737Z",
     "shell.execute_reply": "2025-11-03T14:57:28.734592Z",
     "shell.execute_reply.started": "2025-11-03T14:57:28.720832Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get args: Namespace(checkpoint_iterations=[], compute_cov3D_python=False, config='configs/blender.yml', convert_SHs_python=False, data_device='cuda', debug=False, debug_from=-1, densification_interval=100, densify_from_iter=500, densify_grad_threshold=0.0002, densify_until_iter=15000, detect_anomaly=False, eval=True, feature_lr=0.0025, images='images', ip='127.0.0.1', iterations=30000, lambda_dssim=0.2, model_path='output/blender/ship', opacity_lr=0.05, opacity_reset_interval=3000, percent_dense=0.01, port=6009, position_lr_delay_mult=0.01, position_lr_final=1.6e-06, position_lr_init=0.00016, position_lr_max_steps=30000, quiet=False, random_background=False, resolution=-1, rotation_lr=0.001, save_iterations=[7000, 30000, 30000], scaling_lr=0.005, sh_degree=3, source_path='', start_checkpoint=None, test_iterations=[7000, 30000], white_background=False)\n",
      "\n",
      "source_path: ../OUTPUTS/HR/ship\n",
      "\n",
      "hr_source_path: ../NERF_SYNTHETIC/ship\n",
      "\n",
      "lr_source_path: ../OUTPUTS/LR/ship\n",
      "\n",
      "gt_source_path: ../NERF_SYNTHETIC/ship\n",
      "\n",
      "Optimizing output/blender/ship\n"
     ]
    }
   ],
   "source": [
    "# Set up command line argument parser\n",
    "parser = ArgumentParser(description=\"Training script parameters\")\n",
    "lp = ModelParams(parser)\n",
    "op = OptimizationParams(parser)\n",
    "pp = PipelineParams(parser)\n",
    "parser.add_argument('--ip', type=str, default=\"127.0.0.1\")\n",
    "parser.add_argument('--port', type=int, default=6009)\n",
    "parser.add_argument('--debug_from', type=int, default=-1)\n",
    "parser.add_argument('--detect_anomaly', action='store_true', default=False)\n",
    "parser.add_argument(\"--test_iterations\", nargs=\"+\", type=int, default=[7_000, 30_000])\n",
    "parser.add_argument(\"--save_iterations\", nargs=\"+\", type=int, default=[7_000, 30_000])\n",
    "parser.add_argument(\"--quiet\", action=\"store_true\")\n",
    "parser.add_argument(\"--checkpoint_iterations\", nargs=\"+\", type=int, default=[])\n",
    "parser.add_argument(\"--start_checkpoint\", type=str, default = None)\n",
    "\n",
    "parser.add_argument(\"--config\", type=str, default=None, help=\"Path to configuration YAML file\")\n",
    "\n",
    "# -m : args.model_path\n",
    "args = parser.parse_args([\n",
    "    \"--eval\", \n",
    "    \"--config\", \"configs/blender.yml\"\n",
    "])\n",
    "args.save_iterations.append(args.iterations)\n",
    "\n",
    "print(f\"\\nGet args: {args}\\n\")\n",
    "\n",
    "args = load_config(args)\n",
    "print(\"Optimizing \" + args.model_path)\n",
    "\n",
    "# Initialize system state (RNG)\n",
    "# safe_state(args.quiet)\n",
    "\n",
    "# Start GUI server, configure and run training\n",
    "# network_gui.init(args.ip, args.port)\n",
    "# torch.autograd.set_detect_anomaly(args.detect_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31692915-2ee5-4ecb-8d01-dd68d9b0228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh_degree                : 3\n",
      "source_path              : ../OUTPUTS/HR/ship\n",
      "model_path               : output/blender/ship\n",
      "images                   : images\n",
      "resolution               : -1\n",
      "white_background         : False\n",
      "data_device              : cuda\n",
      "eval                     : True\n",
      "iterations               : 30000\n",
      "position_lr_init         : 0.00016\n",
      "position_lr_final        : 1.6e-06\n",
      "position_lr_delay_mult   : 0.01\n",
      "position_lr_max_steps    : 30000\n",
      "feature_lr               : 0.0025\n",
      "opacity_lr               : 0.05\n",
      "scaling_lr               : 0.005\n",
      "rotation_lr              : 0.001\n",
      "percent_dense            : 0.01\n",
      "lambda_dssim             : 0.2\n",
      "densification_interval   : 100\n",
      "opacity_reset_interval   : 3000\n",
      "densify_from_iter        : 500\n",
      "densify_until_iter       : 15000\n",
      "densify_grad_threshold   : 0.0002\n",
      "random_background        : False\n",
      "convert_SHs_python       : False\n",
      "compute_cov3D_python     : False\n",
      "debug                    : False\n",
      "ip                       : 127.0.0.1\n",
      "port                     : 6009\n",
      "debug_from               : -1\n",
      "detect_anomaly           : False\n",
      "test_iterations          : [7000, 30000]\n",
      "save_iterations          : [7000, 30000, 30000]\n",
      "quiet                    : False\n",
      "checkpoint_iterations    : []\n",
      "start_checkpoint         : None\n",
      "config                   : configs/blender.yml\n",
      "hr_source_dir            : ../NERF_SYNTHETIC\n",
      "lr_source_dir            : ../OUTPUTS/LR\n",
      "vsr_save_dir             : ../OUTPUTS/HR\n",
      "video_save_path          : None\n",
      "vsr_model                : psrt\n",
      "spynet_path              : None\n",
      "vsr_model_path           : None\n",
      "downscale_factor         : 4\n",
      "subpixel                 : bicubic\n",
      "als                      : False\n",
      "num_images_in_sequence   : 100\n",
      "similarity               : feature\n",
      "thres_values             : [45]\n",
      "lambda_tex               : 0.6\n",
      "hr_source_path           : ../NERF_SYNTHETIC/ship\n",
      "lr_source_path           : ../OUTPUTS/LR/ship\n",
      "gt_source_path           : ../NERF_SYNTHETIC/ship\n"
     ]
    }
   ],
   "source": [
    "# 遍历并打印\n",
    "for key, value in vars(args).items():\n",
    "    print(f\"{key:<25}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87dc53a-eb61-4170-8f26-91445c7e9250",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 上采样阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68738322-b4b1-4731-b578-4240a020bccf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model_path: vsr/psrt/experiments/pretrained_models/PSRT_Vimeo.pth\n",
      "model_path: vsr/psrt/experiments/pretrained_models/PSRT_Vimeo.pth\n",
      "\n",
      "spynet_path              : vsr/psrt/experiments/pretrained_models/flownet/spynet_sintel_final-3d2a1287.pth\n",
      "model_path               : vsr/psrt/experiments/pretrained_models/PSRT_Vimeo.pth\n",
      "lr_trainset_path         : ../OUTPUTS/LR/ship/train\n",
      "transform_path           : ../NERF_SYNTHETIC/ship/transforms_train.json\n",
      "vsr_trainset_path        : ../OUTPUTS/HR/ship/train\n",
      "video_save_path          : None\n",
      "num_images_in_sequence   : 100\n",
      "similarity               : feature\n",
      "thres_values             : [45]\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    spynet_path, \n",
    "    model_path, \n",
    "    lr_trainset_path, \n",
    "    transform_path, \n",
    "    vsr_trainset_path, \n",
    "    video_save_path, \n",
    "    num_images_in_sequence, \n",
    "    similarity, \n",
    "    thres_values\n",
    ") = setup_paths_and_params(args) # 读取配置文件， 处理路径\n",
    "\n",
    "'''DEBUG: 打印需要的变量'''\n",
    "vars_dict = {\n",
    "    \"spynet_path\": spynet_path,\n",
    "    \"model_path\": model_path,\n",
    "    \"lr_trainset_path\": lr_trainset_path,\n",
    "    \"transform_path\": transform_path,\n",
    "    \"vsr_trainset_path\": vsr_trainset_path,\n",
    "    \"video_save_path\": video_save_path,\n",
    "    \"num_images_in_sequence\": num_images_in_sequence,\n",
    "    \"similarity\": similarity,\n",
    "    \"thres_values\": thres_values,\n",
    "}\n",
    "for name, value in vars_dict.items():\n",
    "    print(f\"{name:<25}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fbfb003-b354-4a8a-9c40-6ae91e9b04f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading VSR model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VSR model loaded.\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "model_vsr = load_vsr_model(spynet_path=spynet_path, model_path=model_path, device=device)\n",
    "print(\"VSR model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1edd7e54-6c74-4c74-9c27-6a5041069050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载训练数据集\n",
    "if not os.path.exists(vsr_trainset_path):\n",
    "    os.makedirs(vsr_trainset_path)\n",
    "images, names = load_images(lr_trainset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4994dbec-e017-4247-a3a9-854709bab7f5",
   "metadata": {},
   "source": [
    "### process_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b82810-a808-4824-b2f3-1e33e57d1936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c251e879-f353-4fa9-9554-40a97a648420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T14:03:19.346658Z",
     "iopub.status.busy": "2025-11-03T14:03:19.346199Z",
     "iopub.status.idle": "2025-11-03T14:05:54.676935Z",
     "shell.execute_reply": "2025-11-03T14:05:54.675641Z",
     "shell.execute_reply.started": "2025-11-03T14:03:19.346628Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing S: 100 / 100 (100.00%)Upscaling completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import re\n",
    "from archs.psrt_recurrent_arch import BasicRecurrentSwin\n",
    "from basicsr.utils import tensor2img\n",
    "from scene.colmap_loader import read_extrinsics_binary, qvec2rotmat\n",
    "from tqdm import tqdm\n",
    "from vsr.utils_vsr import (\n",
    "    setup_paths_and_params,\n",
    "    load_images,\n",
    "    load_vsr_model,\n",
    "    compute_similarity,\n",
    "    compute_position_distance_ranking,\n",
    "    compute_feature_distance_ranking,\n",
    "    ordering_sim1_thresholding_sim2\n",
    ")\n",
    "\n",
    "# process_S\n",
    "# 创建一个无序不重复元素集\n",
    "created_images = set()\n",
    "# 创建保存文件夹\n",
    "save_path = vsr_trainset_path\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# 创建空列表\n",
    "all_sorted_image_paths = []\n",
    "total_outputs = []\n",
    "\n",
    "# 两种“相似”的定义\n",
    "if similarity == 'feature':\n",
    "    # 将compute_feature_distance_ranking(images)返回结果放到数组中\n",
    "    feature_rankings = np.array(compute_feature_distance_ranking(images))\n",
    "    ''' \n",
    "    feature_distance_rankings = [\n",
    "        [[rank_0, dist_0], [rank_1, dist_1], [rank_2, dist_2], ...],  # 对第1张图的排名\n",
    "        [[rank_0, dist_0], [rank_1, dist_1], [rank_2, dist_2], ...],  # 对第2张图的排名\n",
    "        ...\n",
    "    ]\n",
    "    '''\n",
    "    sorted_indices = ordering_sim1_thresholding_sim2(images, 0, 180, feature_rankings, None, similarity)\n",
    "elif similarity == 'pose':\n",
    "    position_rankings = np.array(compute_position_distance_ranking(images, transform_path))\n",
    "    sorted_indices = ordering_sim1_thresholding_sim2(images, 0, 180, position_rankings, None, similarity)\n",
    "\n",
    "# Inference VSR and save images\n",
    "# 将已排序序列按num_images_in_sequence为步进分为许多序列块（chunk_indices）\n",
    "for i in range(0, len(sorted_indices), num_images_in_sequence):\n",
    "    chunk_indices = sorted_indices[i:i + num_images_in_sequence]\n",
    "\n",
    "    # Handle case where the last chunk is smaller\n",
    "    # 末端不足num_images_in_sequence长度的块，重新定义为最后num_images_in_sequence个图片\n",
    "    if len(chunk_indices) < num_images_in_sequence:\n",
    "        chunk_indices = sorted_indices[-num_images_in_sequence:]\n",
    "\n",
    "    # Prepare batch of images with context (like in code2)\n",
    "    # 添加序列块上下文（VSR模型需要参考上下文）\n",
    "    batch_imgs = [images[idx] for idx in chunk_indices]\t# 列表推导式\n",
    "    batch_imgs = [batch_imgs[0]] + batch_imgs + [batch_imgs[-1]] # 重复首尾作为上下文\n",
    "    # 图片序列格式变化，用于模型适配\n",
    "    batch_imgs = np.stack(batch_imgs).transpose(0, 3, 1, 2)  # Convert to NCHW format\n",
    "    batch_imgs = torch.from_numpy(batch_imgs).float().div(255.0).unsqueeze(0).to(device)\n",
    "\n",
    "    # Generate outputs\n",
    "    # 用VSR模型进行超分操作，并保存输出\n",
    "    with torch.no_grad():   # 禁用梯度追踪， 不计算梯度\n",
    "        outputs = model_vsr(batch_imgs).squeeze(0)[1:-1]    # 删除0维， 删除首尾帧\n",
    "    total_outputs.append(outputs)\n",
    "\n",
    "    # 格式转换\n",
    "    outputs = [tensor2img(outputs[idx], rgb2bgr=True, min_max=(0, 1)) for idx in range(outputs.shape[0])]\n",
    "    # Save output images\n",
    "    for idx in range(len(chunk_indices)):\n",
    "        output_name = names[chunk_indices[idx]]\n",
    "        output_path = os.path.join(save_path, output_name)\n",
    "        if output_name not in created_images:\n",
    "            Image.fromarray(outputs[idx]).save(output_path)\n",
    "            created_images.add(output_name)\n",
    "            all_sorted_image_paths.append(output_path)\n",
    "\n",
    "    print(f\"\\rProcessing S: {len(created_images)} / {len(images)} ({(len(created_images) / len(images)) * 100:.2f}%)\", end=\"\", flush=True)\n",
    "\n",
    "total_outputs = torch.cat(total_outputs, dim=0)\n",
    "\n",
    "# return all_sorted_image_paths, total_outputs\n",
    "print(\"\\nUpscaling completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e055a7a5-30cb-40d5-bfe7-77578bf30cbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3DGS训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b652dcb2-419a-4133-b49d-77aed90b463f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T14:57:35.817102Z",
     "iopub.status.busy": "2025-11-03T14:57:35.816253Z",
     "iopub.status.idle": "2025-11-03T14:57:35.826294Z",
     "shell.execute_reply": "2025-11-03T14:57:35.825161Z",
     "shell.execute_reply.started": "2025-11-03T14:57:35.817040Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lambda_tex=0.40\n",
    "subpixel=\"avg\"\n",
    "(\n",
    "    dataset, opt, pipe, testing_iterations, saving_iterations, \n",
    "    checkpoint_iterations, checkpoint, debug_from, lambda_tex, subpixel\n",
    ") = (\n",
    "    lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, \n",
    "    args.checkpoint_iterations, args.start_checkpoint, args.debug_from, args.lambda_tex, \n",
    "    args.subpixel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95aa2e49-1d1a-4dc1-92e6-52b7b2f7e27d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T14:57:36.581737Z",
     "iopub.status.busy": "2025-11-03T14:57:36.581177Z",
     "iopub.status.idle": "2025-11-03T14:57:36.595788Z",
     "shell.execute_reply": "2025-11-03T14:57:36.594793Z",
     "shell.execute_reply.started": "2025-11-03T14:57:36.581702Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder: output/blender/ship\n"
     ]
    }
   ],
   "source": [
    "# 1. 准备日志和输出目录\n",
    "first_iter = 0\n",
    "\n",
    "if not args.model_path:\n",
    "    if os.getenv('OAR_JOB_ID'):\n",
    "        unique_str=os.getenv('OAR_JOB_ID')\n",
    "    else:\n",
    "        unique_str = str(uuid.uuid4())\n",
    "    args.model_path = os.path.join(\"./output/\", unique_str[0:10])\n",
    "\n",
    "# Set up output folder\n",
    "print(\"Output folder: {}\".format(args.model_path))\n",
    "os.makedirs(args.model_path, exist_ok = True)\n",
    "with open(os.path.join(args.model_path, \"cfg_args\"), 'w') as cfg_log_f:\n",
    "    cfg_log_f.write(str(Namespace(**vars(args))))\n",
    "\n",
    "# Create Tensorboard writer\n",
    "tb_writer = None\n",
    "if TENSORBOARD_FOUND:\n",
    "    tb_writer = SummaryWriter(args.model_path)\n",
    "else:\n",
    "    print(\"Tensorboard not available: not logging progress\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cda336-dd52-45b4-8929-fd96a4b1f0ba",
   "metadata": {},
   "source": [
    "**注**：args.model_path指的是3D高斯模型输出路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b357cad4-e0f5-4210-80d0-c6a81a0eea1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T14:57:38.222342Z",
     "iopub.status.busy": "2025-11-03T14:57:38.221645Z",
     "iopub.status.idle": "2025-11-03T14:57:38.229840Z",
     "shell.execute_reply": "2025-11-03T14:57:38.228357Z",
     "shell.execute_reply.started": "2025-11-03T14:57:38.222283Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. 初始化高斯模型\n",
    "gaussians = GaussianModel(dataset.sh_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e896df9-78af-4089-8410-836eaf2259a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T14:57:38.981465Z",
     "iopub.status.busy": "2025-11-03T14:57:38.980760Z",
     "iopub.status.idle": "2025-11-03T14:58:22.823732Z",
     "shell.execute_reply": "2025-11-03T14:58:22.822800Z",
     "shell.execute_reply.started": "2025-11-03T14:57:38.981406Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found transforms_train.json file, assuming Blender data set!\n",
      "Reading Training Transforms\n",
      "Reading Test Transforms\n",
      "Loading Training Cameras\n",
      "Loading Test Cameras\n",
      "Number of points at initialisation :  100000\n"
     ]
    }
   ],
   "source": [
    "# 3. 创建场景（加载训练相机）\n",
    "scene = Scene(dataset, gaussians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf6ba7a-ec7f-400b-8f73-a841de9d2140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T14:59:32.781189Z",
     "iopub.status.busy": "2025-11-03T14:59:32.780464Z",
     "iopub.status.idle": "2025-11-03T14:59:32.813585Z",
     "shell.execute_reply": "2025-11-03T14:59:32.812548Z",
     "shell.execute_reply.started": "2025-11-03T14:59:32.781128Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4. 设置优化器\n",
    "gaussians.training_setup(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "814f3d72-67a5-4be6-9e70-f57ce57f8644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T14:59:51.776814Z",
     "iopub.status.busy": "2025-11-03T14:59:51.775956Z",
     "iopub.status.idle": "2025-11-03T14:59:51.784405Z",
     "shell.execute_reply": "2025-11-03T14:59:51.783408Z",
     "shell.execute_reply.started": "2025-11-03T14:59:51.776753Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. 恢复检查点（如果提供）\n",
    "if checkpoint:\n",
    "    (model_params, first_iter) = torch.load(checkpoint)\n",
    "    gaussians.restore(model_params, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59d1a34c-a04b-47b3-aab0-be095e6d63c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T15:02:58.094889Z",
     "iopub.status.busy": "2025-11-03T15:02:58.093547Z",
     "iopub.status.idle": "2025-11-03T15:02:58.115851Z",
     "shell.execute_reply": "2025-11-03T15:02:58.114809Z",
     "shell.execute_reply.started": "2025-11-03T15:02:58.094815Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_report(tb_writer, iteration, Ll1, loss, l1_loss, elapsed, testing_iterations, scene, renderFunc, renderArgs):\n",
    "    if tb_writer:\n",
    "        tb_writer.add_scalar('train_loss_patches/l1_loss', Ll1.item(), iteration)\n",
    "        tb_writer.add_scalar('train_loss_patches/total_loss', loss.item(), iteration)\n",
    "        tb_writer.add_scalar('iter_time', elapsed, iteration)\n",
    "\n",
    "    # Report test and samples of training set\n",
    "    if iteration in testing_iterations:\n",
    "        torch.cuda.empty_cache()\n",
    "        validation_configs = ({'name': 'test', 'cameras' : scene.getTestCameras()}, \n",
    "                              {'name': 'train', 'cameras' : [scene.getTrainCameras()[idx % len(scene.getTrainCameras())] for idx in range(5, 30, 5)]})\n",
    "\n",
    "        for config in validation_configs:\n",
    "            if config['cameras'] and len(config['cameras']) > 0:\n",
    "                l1_test = 0.0\n",
    "                psnr_test = 0.0\n",
    "                for idx, viewpoint in enumerate(config['cameras']):\n",
    "                    image = torch.clamp(renderFunc(viewpoint, scene.gaussians, *renderArgs)[\"render\"], 0.0, 1.0)\n",
    "                    gt_image = torch.clamp(viewpoint.original_image.to(\"cuda\"), 0.0, 1.0)\n",
    "                    if tb_writer and (idx < 5):\n",
    "                        tb_writer.add_images(config['name'] + \"_view_{}/render\".format(viewpoint.image_name), image[None], global_step=iteration)\n",
    "                        if iteration == testing_iterations[0]:\n",
    "                            tb_writer.add_images(config['name'] + \"_view_{}/ground_truth\".format(viewpoint.image_name), gt_image[None], global_step=iteration)\n",
    "                    l1_test += l1_loss(image, gt_image).mean().double()\n",
    "                    psnr_test += psnr(image, gt_image).mean().double()\n",
    "                psnr_test /= len(config['cameras'])\n",
    "                l1_test /= len(config['cameras'])          \n",
    "                print(\"\\n[ITER {}] Evaluating {}: L1 {} PSNR {}\".format(iteration, config['name'], l1_test, psnr_test))\n",
    "                if tb_writer:\n",
    "                    tb_writer.add_scalar(config['name'] + '/loss_viewpoint - l1_loss', l1_test, iteration)\n",
    "                    tb_writer.add_scalar(config['name'] + '/loss_viewpoint - psnr', psnr_test, iteration)\n",
    "\n",
    "        if tb_writer:\n",
    "            tb_writer.add_histogram(\"scene/opacity_histogram\", scene.gaussians.get_opacity, iteration)\n",
    "            tb_writer.add_scalar('total_points', scene.gaussians.get_xyz.shape[0], iteration)\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "473ef897-2a12-485c-a0e0-f25949bb84b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T15:08:03.396152Z",
     "iopub.status.busy": "2025-11-03T15:08:03.395465Z",
     "iopub.status.idle": "2025-11-03T15:16:03.709141Z",
     "shell.execute_reply": "2025-11-03T15:16:03.707314Z",
     "shell.execute_reply.started": "2025-11-03T15:08:03.396087Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009469985961914062,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Training progress",
       "rate": null,
       "total": 29998,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9d63fcf6c341e2a996b2010cd97fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training progress:   0%|          | 0/29998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ITER 7000] Evaluating test: L1 0.014479106673970819 PSNR 29.091571922302247\n",
      "\n",
      "[ITER 7000] Evaluating train: L1 0.008679708186537028 PSNR 33.63783149719239\n",
      "\n",
      "[ITER 7000] Saving Gaussians\n",
      "\n",
      "[ITER 30000] Evaluating test: L1 0.013914167943876237 PSNR 29.39746416091919\n",
      "\n",
      "[ITER 30000] Evaluating train: L1 0.006262173224240542 PSNR 36.298919677734375\n",
      "\n",
      "[ITER 30000] Saving Gaussians\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]\n",
    "background = torch.tensor(bg_color, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "iter_start = torch.cuda.Event(enable_timing = True)\n",
    "iter_end = torch.cuda.Event(enable_timing = True)\n",
    "\n",
    "viewpoint_stack = None\n",
    "avg_kernel = torch.nn.AvgPool2d(4, stride=4)  \n",
    "\n",
    "ema_loss_for_log = 0.0\n",
    "progress_bar = tqdm(range(first_iter, opt.iterations), desc=\"Training progress\")\n",
    "first_iter += 1\n",
    "for iteration in range(first_iter, opt.iterations + 1):        \n",
    "    if network_gui.conn == None:\n",
    "        network_gui.try_connect()\n",
    "    while network_gui.conn != None:\n",
    "        try:\n",
    "            net_image_bytes = None\n",
    "            custom_cam, do_training, pipe.convert_SHs_python, pipe.compute_cov3D_python, keep_alive, scaling_modifer = network_gui.receive()\n",
    "            if custom_cam != None:\n",
    "                net_image = render(custom_cam, gaussians, pipe, background, scaling_modifer)[\"render\"]\n",
    "                net_image_bytes = memoryview((torch.clamp(net_image, min=0, max=1.0) * 255).byte().permute(1, 2, 0).contiguous().cpu().numpy())\n",
    "            network_gui.send(net_image_bytes, dataset.source_path)\n",
    "            if do_training and ((iteration < int(opt.iterations)) or not keep_alive):\n",
    "                break\n",
    "        except Exception as e:\n",
    "            network_gui.conn = None\n",
    "\n",
    "    iter_start.record()\n",
    "\n",
    "    gaussians.update_learning_rate(iteration)\n",
    "\n",
    "    # Every 1000 its we increase the levels of SH up to a maximum degree\n",
    "    if iteration % 1000 == 0:\n",
    "        gaussians.oneupSHdegree()\n",
    "\n",
    "    ### HR scale\n",
    "    # Pick a random Camera\n",
    "    if not viewpoint_stack:\n",
    "        viewpoint_stack = scene.getTrainCameras().copy()\n",
    "    idx_cam = randint(0, len(viewpoint_stack)-1)\n",
    "    viewpoint_cam = viewpoint_stack.pop(idx_cam)\n",
    "\n",
    "    # Render\n",
    "    if (iteration - 1) == debug_from:\n",
    "        pipe.debug = True\n",
    "\n",
    "    bg = torch.rand((3), device=\"cuda\") if opt.random_background else background\n",
    "\n",
    "    render_pkg = render(viewpoint_cam, gaussians, pipe, bg)\n",
    "    image, viewspace_point_tensor, visibility_filter, radii = render_pkg[\"render\"], render_pkg[\"viewspace_points\"], render_pkg[\"visibility_filter\"], render_pkg[\"radii\"]\n",
    "\n",
    "    # Loss\n",
    "    gt_image = viewpoint_cam.original_image.cuda()\n",
    "    Ll1 = l1_loss(image, gt_image)\n",
    "    loss_tex = (1.0 - opt.lambda_dssim) * Ll1 + opt.lambda_dssim * (1.0 - ssim(image, gt_image))\n",
    "\n",
    "    ### LR scale\n",
    "    # Pick a random Camera\n",
    "    if subpixel == 'avg':\n",
    "        image_avg = avg_kernel(image)\n",
    "    elif subpixel == 'bicubic':\n",
    "        image_avg = torch.nn.functional.interpolate(image.unsqueeze(0), scale_factor=0.25, mode='bicubic', antialias=True).squeeze(0)\n",
    "    else:\n",
    "        raise Exception(\"Wrong sub-pixel option\")\n",
    "\n",
    "    gt_image_lr = viewpoint_cam.original_image_lr.cuda()\n",
    "    if image_avg.shape != gt_image_lr.shape:\n",
    "        # import torch.nn.functional as F\n",
    "        gt_image_lr = torch.nn.functional.interpolate(gt_image.unsqueeze(0), size=image_avg.size()[-2:], mode='bicubic', antialias=True).squeeze(0)\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "    # Loss\n",
    "    Ll1_sp = l1_loss(image_avg, gt_image_lr)\n",
    "    loss_sp = (1.0 - opt.lambda_dssim) * Ll1_sp + opt.lambda_dssim * (1.0 - ssim(image_avg, gt_image_lr))\n",
    "    ###\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    if iteration == opt.iterations - 5000:\n",
    "        import torchvision.transforms as transforms\n",
    "        from PIL import Image\n",
    "\n",
    "        to_pil_image = transforms.ToPILImage()\n",
    "\n",
    "        gt_image_lr_pil = to_pil_image(gt_image_lr)\n",
    "        gt_image_lr_pil.save(\"gt_image_lr_pil.png\")\n",
    "\n",
    "        image_avg_pil  = to_pil_image(image_avg)\n",
    "        image_avg_pil.save(\"image_avg_pil.png\")\n",
    "\n",
    "    lambda_tex_scheduled = lambda_tex\n",
    "    loss = (1.0 - lambda_tex_scheduled) * loss_sp + lambda_tex_scheduled * loss_tex\n",
    "    loss.backward()\n",
    "\n",
    "    iter_end.record()\n",
    "\n",
    "    # 由高斯点云渲染3D模型\n",
    "    with torch.no_grad():\n",
    "        # Progress bar\n",
    "        ema_loss_for_log = 0.4 * loss.item() + 0.6 * ema_loss_for_log\n",
    "        if iteration % 10 == 0:\n",
    "            progress_bar.set_postfix({\"Loss\": f\"{ema_loss_for_log:.{7}f}\"})\n",
    "            progress_bar.update(10)\n",
    "        if iteration == opt.iterations:\n",
    "            progress_bar.close()\n",
    "\n",
    "        # Log and save\n",
    "        training_report(tb_writer, iteration, Ll1, loss, l1_loss, iter_start.elapsed_time(iter_end), testing_iterations, scene, render, (pipe, background))\n",
    "        if (iteration in saving_iterations):\n",
    "            print(\"\\n[ITER {}] Saving Gaussians\".format(iteration))\n",
    "            scene.save(iteration)\n",
    "\n",
    "        # Densification\n",
    "        # 在细节不足或误差大的地方自动“加点”； 在冗余或不可见区域“删点”。\n",
    "        if iteration < opt.densify_until_iter:\n",
    "            # Keep track of max radii in image-space for pruning\n",
    "            gaussians.max_radii2D[visibility_filter] = torch.max(gaussians.max_radii2D[visibility_filter], radii[visibility_filter])\n",
    "            gaussians.add_densification_stats(viewspace_point_tensor, visibility_filter)\n",
    "\n",
    "            if iteration > opt.densify_from_iter and iteration % opt.densification_interval == 0:\n",
    "                size_threshold = 20 if iteration > opt.opacity_reset_interval else None\n",
    "                gaussians.densify_and_prune(opt.densify_grad_threshold, 0.005, scene.cameras_extent, size_threshold)\n",
    "\n",
    "            if iteration % opt.opacity_reset_interval == 0 or (dataset.white_background and iteration == opt.densify_from_iter):\n",
    "                gaussians.reset_opacity()\n",
    "\n",
    "        # Optimizer step\n",
    "        if iteration < opt.iterations:\n",
    "            gaussians.optimizer.step()\n",
    "            gaussians.optimizer.zero_grad(set_to_none = True)\n",
    "\n",
    "        # 输出保存高精度3D Gaussian点云模型\n",
    "        if (iteration in checkpoint_iterations):\n",
    "            print(\"\\n[ITER {}] Saving Checkpoint\".format(iteration))\n",
    "            torch.save((gaussians.capture(), iteration), scene.model_path + \"/chkpnt\" + str(iteration) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b519f47-13fd-4185-8b70-ea4947ee680f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
